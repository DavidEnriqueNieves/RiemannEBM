{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('../')  \n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from dataclasses import dataclass\n",
    "import einops\n",
    "from plotly.subplots import make_subplots\n",
    "from model import MLP_ELU_convex\n",
    "import hydra\n",
    "import plotly.figure_factory as ff\n",
    "from metrics import RiemannianMetric, DiagonalRiemannianMetric, Method2Metric, Method3Metric\n",
    "from utils.toy_dataset import GaussianMixture\n",
    "from train_EBM_geodesic import get_metrics_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93bfc72",
   "metadata": {},
   "source": [
    "This is a notebook to demonstrate the plotting of metric tensors quantities over some 2D domain, with those quantities being the eigenvalue magnitudes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10fd01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # %%\n",
    "DEVICE: str = \"cuda:1\"\n",
    "\n",
    "NB_GAUSSIANS = 200\n",
    "RADIUS = 8\n",
    "mean_ = (torch.linspace(0, 180, NB_GAUSSIANS + 1)[0:-1] * math.pi / 180)\n",
    "MEAN = RADIUS * torch.stack([torch.cos(mean_), torch.sin(mean_)], dim=1)\n",
    "COVAR = torch.tensor([[1., 0], [0, 1.]]).unsqueeze(0).repeat(len(MEAN), 1, 1)\n",
    "\n",
    "x_p, y_p = torch.meshgrid(torch.linspace(-10, 10, 100), torch.linspace(-2.5, 10, 62), indexing='xy')\n",
    "pos = torch.cat([x_p.flatten().unsqueeze(1), y_p.flatten().unsqueeze(1)], dim=1).to(DEVICE)\n",
    "\n",
    "## Defining the mixture\n",
    "weight_1 = (torch.ones(NB_GAUSSIANS) / NB_GAUSSIANS)\n",
    "mixture_1 = GaussianMixture(center_data=MEAN, covar=COVAR, weight=weight_1).to(DEVICE)\n",
    "mixture_1 = mixture_1.to(DEVICE)\n",
    "\n",
    "## compute the energy landscape\n",
    "energy_landscape_1: Tensor = mixture_1.energy(pos)\n",
    "print(f\"{energy_landscape_1.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "num_samples: int = int(1000)\n",
    "sample_dataset = mixture_1.sample(num_samples).to(DEVICE)\n",
    "reference_samples = mixture_1.sample(num_samples)\n",
    "## ebm-based metric\n",
    "loaded: dict = torch.load(\"../tutorial/EBM_mixture1.pth\", weights_only=False)\n",
    "\n",
    "ebm = loaded['type']()\n",
    "ebm.load_state_dict(loaded['weight'])\n",
    "ebm.to(DEVICE)\n",
    "\n",
    "target_metric_cfg: dict = {\n",
    "\"_target_\": \"train_EBM_geodesic.Method2Metric\",\n",
    "      \"a_num\": 20.0,\n",
    "      \"b_num\": 0.01,\n",
    "      \"eps\": 1e-6,\n",
    "      \"eta\": 0,\n",
    "      \"mu\": 1.0,\n",
    "      \"alpha_fn_choice\": \"linear\"\n",
    "}\n",
    "\n",
    "metric_dict: dict[str, RiemannianMetric] = get_metrics_dict(\n",
    "        mixture_1,\n",
    "        pos,\n",
    "        ebm,\n",
    "        reference_samples,\n",
    "        DEVICE)\n",
    "\n",
    "metric_dict[target_metric_cfg[\"_target_\"]] = hydra.utils.instantiate(target_metric_cfg, ebm=ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2204f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos.requires_grad_(True)\n",
    "\n",
    "\n",
    "metric_gouts: dict[str, Tensor] = {}\n",
    "\n",
    "for metric_str, metric_fn in metric_dict.items():\n",
    "    print(f\"{metric_str}, {metric_fn}\")\n",
    "    output_tnsr: Tensor = metric_fn.g(x_t=pos)\n",
    "    metric_gouts[metric_str] = output_tnsr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2_metric_is_diagonal: bool = torch.all(metric_gouts[\"train_EBM_geodesic.Method2Metric\"][:, 1, 0] == 0) and torch.all(metric_gouts[\"train_EBM_geodesic.Method2Metric\"][:, 0, 1] == 0)\n",
    "# m2_metric_is_diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_gouts[\"train_EBM_geodesic.Method2Metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name, tnsr in metric_gouts.items():\n",
    "    print(f\"Metric: {metric_name}, Tensor shape: {tnsr.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AnimationData:\n",
    "    color_tuple: tuple\n",
    "    size: int\n",
    "    symbol: str\n",
    "    latex_label: str\n",
    "\n",
    "normed_m2_color: Tensor = torch.tensor([147, 112, 219]) \n",
    "normed_m3_color: Tensor = torch.tensor([128, 0, 128])\n",
    "m2_color: tuple = tuple(normed_m2_color.tolist())\n",
    "m3_color: tuple = tuple(normed_m3_color.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9821561",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_color: dict[str, AnimationData] = {\n",
    "    \"conf_ebm_logp\": AnimationData(color_tuple=(66, 133, 244), size=150, symbol='.', latex_label=r\"$\\mathbf{G}_{E_{\\theta}}$\"),\n",
    "    \"conf_ebm_invp\": AnimationData(color_tuple=(52, 168, 83), size=150, symbol='.', latex_label=r\"$\\mathbf{G}_{1/p_{\\theta}}$\"),\n",
    "    \"diag_rbf_invp\": AnimationData(color_tuple=(234, 67, 53), size=150, symbol='.', latex_label=r\"$\\mathbf{G}_{RBF}$\"),\n",
    "    \"diag_land_invp\": AnimationData(color_tuple=(251, 188, 5), size=150, symbol='.', latex_label=r\"$\\mathbf{G}_{LAND}$\"),\n",
    "    \"conf_true_logp\": AnimationData(color_tuple=(0, 0, 0), size=150, symbol='+', latex_label=r\"$\\mathbf{G}_{E_{\\mathcal{M}}}$\"),\n",
    "    \"conf_true_invp\": AnimationData(color_tuple=(0, 0, 0), size=150, symbol='x', latex_label=r\"$\\mathbf{G}_{1/p_{\\mathcal{M}}}$\"),\n",
    "    \"train_EBM_geodesic.Method2Metric\": AnimationData(color_tuple=m2_color, size=150, symbol='.', latex_label=r\"$\\mathbf{G}_{M2}$\"),\n",
    "    \"train_EBM_geodesic.Method3Metric\": AnimationData(color_tuple=m3_color, size=150, symbol='.', latex_label=r\"$\\mathbf{G}_{M3}$\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_value_titles: list[str] = [f\"{dico_color[metric].latex_label} Norm\" for metric in dico_color.keys()]\n",
    "eigvalue_titles: list[str] = [f\"Metric: {dico_color[metric].latex_label} - Eigenvalues\" for metric in dico_color.keys()]\n",
    "all_subplot_titles: list[str] = []\n",
    "all_subplot_titles.extend(raw_value_titles) \n",
    "all_subplot_titles.extend(eigvalue_titles)\n",
    "\n",
    "fig: go.Figure = make_subplots(rows=2, cols=len(metric_gouts), subplot_titles=all_subplot_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding raw value heatmaps\n",
    "x_tnsr_detach: Tensor = pos[:, 0].detach().cpu().numpy()\n",
    "y_tnsr_detach: Tensor = pos[:, 1].detach().cpu().numpy()\n",
    "# TODO: add aserts here \n",
    "B: int = int(x_tnsr_detach.shape[0])\n",
    "\n",
    "\n",
    "# Adding frobenius norm \n",
    "for i, (metric_str, tnsr) in enumerate(metric_gouts.items()):\n",
    "    print(f\"{i=}\")\n",
    "    print(f\"{metric_str=}\")\n",
    "    print(f\"{tnsr.shape=}\")\n",
    "\n",
    "    if tnsr.shape != (B,):\n",
    "        dims: int = len(tnsr.shape)\n",
    "\n",
    "        z_tnsr: Tensor = None\n",
    "        if dims == 1:\n",
    "            z_tnsr = tnsr**2\n",
    "        if dims == 2:\n",
    "            z_tnsr = torch.linalg.norm(tnsr, dim=1)\n",
    "        elif dims==3:\n",
    "            z_tnsr = torch.linalg.norm(tnsr, dim=(1,2))\n",
    "        else:\n",
    "            raise ValueError(f\"Warning! Found anomalous shape of {tnsr.shape}\")\n",
    "        \n",
    "        assert z_tnsr.shape == (B,), f\"Error! Expected tensor of shape {(B,)}, but found one of shape {z_tnsr.shape}\"\n",
    "    else:\n",
    "        z_tnsr = tnsr\n",
    "\n",
    "    # break\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            x=x_tnsr_detach,\n",
    "            y=y_tnsr_detach,\n",
    "            z = z_tnsr.detach().cpu().numpy()\n",
    "        ),\n",
    "        row=1,\n",
    "        col=i+1\n",
    "    )\n",
    "\n",
    "# Adding Aggregation of matrices\n",
    "for i, (metric_str, tnsr) in enumerate(metric_gouts.items()):\n",
    "    print(f\"{i=}\")\n",
    "    print(f\"{metric_str=}\")\n",
    "    print(f\"{tnsr.shape=}\")\n",
    "\n",
    "    if tnsr.shape != (B,):\n",
    "        dims: int = len(tnsr.shape)\n",
    "        z_tnsr: Tensor = None\n",
    "        if dims == 1:\n",
    "            z_tnsr = tnsr\n",
    "        if dims == 2:\n",
    "            z_tnsr = tnsr.mean(dim=1)\n",
    "        elif dims == 3:\n",
    "            eigvals, eigvecs = torch.linalg.eig(tnsr)\n",
    "            print(f\"{eigvals.shape=}\")\n",
    "            z_tnsr: Tensor = torch.abs(eigvals.mean(dim=1))\n",
    "        else:\n",
    "            raise ValueError(f\"Warning! Found anomalous shape of {tnsr.shape}\")\n",
    "        \n",
    "        assert z_tnsr.shape == (B,), f\"Error! Expected tensor of shape {(B,)}, but found one of shape {z_tnsr.shape}\"\n",
    "    else:\n",
    "        z_tnsr = tnsr\n",
    "\n",
    "    # break\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            x=x_tnsr_detach,\n",
    "            y=y_tnsr_detach,\n",
    "            z = z_tnsr.detach().cpu().numpy()\n",
    "        ),\n",
    "        row=2,\n",
    "        col=i+1\n",
    "    )\n",
    "fig.show()\n",
    "fig.write_html(\"./all_metrics.html\", include_mathjax=\"cdn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a076db",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_metric_cfg: dict = {\n",
    "\"_target_\": \"train_EBM_geodesic.Method3Metric\",\n",
    "      \"eps\": 1e-6,\n",
    "      \"eta\": 5,\n",
    "      \"mu\": 1.0,\n",
    "      \"beta\": 0.004,\n",
    "      \"alpha_fn_choice\": \"linear\"\n",
    "}\n",
    "\n",
    "\n",
    "toy_metric: Method2Metric = hydra.utils.instantiate(target_metric_cfg, ebm=ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_score, met_energy =  toy_metric.get_score_n_nrg(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b40ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{score_on_pos.shape=}\")\n",
    "grad_outer_prod: Tensor = torch.einsum('bi,bj->bij', met_score, met_score)\n",
    "\n",
    "\n",
    "eigvals, eigvecs = torch.linalg.eig(grad_outer_prod)\n",
    "print(f\"{eigvals.shape=}\")\n",
    "print(f\"{met_score.shape=}\")\n",
    "print(f\"{torch.norm(met_score, dim=1, p=2)[:10]**2=}\")\n",
    "print(f\"{eigvals[:10]=}\")\n",
    "assert torch.all(eigvals.imag.abs() < 1e-6), \"Complex eigenvalues found in grad_outer_prod\"\n",
    "assert torch.all(eigvals.real >= -1.0e-5), f\"Non-positive eigenvalues found in grad_outer_prod with min {eigvals.real.min().item()}. {eigvals=}\"\n",
    "\n",
    "# print(f\"{grad_outer_prod.shape=}\")\n",
    "alpha_val: Tensor = toy_metric.alpha_fn(met_energy).to(pos.device)\n",
    "\n",
    "min_en: float = met_energy.real.min().item()\n",
    "print(f\"{min_en=}\")\n",
    "max_en: float = met_energy.real.max().item()\n",
    "print(f\"{max_en=}\")\n",
    "\n",
    "mult_factor: float = 10.0\n",
    "alpha_a: float = mult_factor * (1 / (max_en - min_en + toy_metric.eps))\n",
    "alpha_b: float = min_en\n",
    "\n",
    "alpha_lb: float = 5.0\n",
    "\n",
    "toy_metric.alpha_a = alpha_a\n",
    "toy_metric.alpha_b = alpha_b\n",
    "toy_metric.alpha_lb = alpha_lb\n",
    "\n",
    "alpha_val: Tensor = toy_metric.alpha_fn(met_energy).to(pos.device)\n",
    "# assert torch.max(alpha_val).item() < mult_factor, f\"Unexpectedly high alpha values found with max {alpha_val.max().item()}. {alpha_val=}\"\n",
    "\n",
    "assert torch.min(alpha_val).item() >= 0, f\"Non-positive alpha values found with min {alpha_val.min().item()}. {alpha_val=}\"\n",
    "\n",
    "print(f\"{alpha_val.max().item()=}\")\n",
    "print(f\"{alpha_val.min().item()=}\")\n",
    "\n",
    "alpha_val = einops.rearrange(alpha_val, 'b 1 -> b 1 1')\n",
    "assert torch.all(alpha_val.real >= 0), f\"Non-positive alpha values found with min {alpha_val.real.min().item()}. {alpha_val=}\"\n",
    "\n",
    "# print(f\"{alpha_val.shape=}\")\n",
    "\n",
    "# give it a 'batch' dimension to add with grad_outer_prod\n",
    "I_mat: Tensor = einops.rearrange(torch.eye(2).to(pos.device), 'i j -> 1 i j')\n",
    "# print(f\"{I_mat.shape=}\")\n",
    "# print(f\"{grad_outer_prod.shape=}\")\n",
    "# print(f\"{alpha_val.shape=}\")\n",
    "\n",
    "print(f\"{toy_metric.mu=}\")\n",
    "print(f\"{toy_metric.eta=}\")\n",
    "A_pre: Tensor = (toy_metric.mu * I_mat + toy_metric.eta * grad_outer_prod)\n",
    "\n",
    "A_mat: Tensor =  alpha_val * A_pre \n",
    "\n",
    "A_mat: Tensor = A_mat \n",
    "# print(f\"{A_mat.shape=}\")\n",
    "print(f\"{A_mat.shape=}\")\n",
    "eigvals, eigvecs = torch.linalg.eig(A_mat)\n",
    "print(f\"{eigvecs.shape=}\")\n",
    "\n",
    "assert torch.all(eigvecs.imag.abs() < 1e-6), \"Complex eigenvalues found in A_mat\"\n",
    "assert torch.all(eigvals.real >= 0), f\"Non-positive eigenvalues found in A_mat with min {eigvals.real.min().item()}. {eigvals=}\"\n",
    "\n",
    "print(f\"Min eigenvalue of A_mat: {eigvals.real.min().item()}\")\n",
    "print(f\"Max eigenvalue of A_mat: {eigvals.real.max().item()}\")\n",
    "\n",
    "A_inv: Tensor = torch.linalg.inv(A_mat)\n",
    "\n",
    "eigvals_inv, eigvecs_inv = torch.linalg.eig(A_inv)\n",
    "assert torch.all(eigvecs_inv.imag.abs() < 1e-6), \"Complex eigenvalues found in A_inv\"\n",
    "assert torch.all(eigvals_inv.real >= 0), f\"Non-positive eigenvalues found in A_inv with min {eigvals_inv.real.min().item()}. {eigvals_inv=}\"\n",
    "\n",
    "\n",
    "# Method 3 Stuff\n",
    "\n",
    "\n",
    "grad_outer_prod: Tensor = torch.einsum('bi,bj->bij', met_score, met_score)\n",
    "# taking the inner product of the score with itself under A(x)\n",
    "inner_prods_pre: Tensor = torch.einsum('bij, bj -> bi', A_mat, met_score)\n",
    "inner_prods: Tensor = torch.einsum('bi,bi->b', inner_prods_pre, met_score)\n",
    "\n",
    "# Computing the inverse of A(x) cheaply using the Sherman-Morrison formula\n",
    "# inv_met: Tensor = (self.eta / self.mu) * I_mat - \\\n",
    "#     (\n",
    "#         (grad_outer_prod) / \\\n",
    "#         ((self.mu / self.eta) + inner_prods)\n",
    "#     )\n",
    "\n",
    "# yes, I know there is an easier way of doing this but I just want this to work \n",
    "inv_met: Tensor = torch.linalg.inv(A_mat)\n",
    "\n",
    "I_mat: Tensor = einops.rearrange(torch.eye(2), 'i j -> 1 i j')\n",
    "I_mat = I_mat.to(pos.device)\n",
    "\n",
    "eigvecs, eigvals_inv_met = torch.linalg.eig(inv_met)\n",
    "assert torch.all(inner_prods > 0), \"Negative values found in inner_prods, which could lead to instability. Consider increasing eps or checking the energy landscape for very low values.\"\n",
    "\n",
    "\n",
    "print(f\"{torch.isnan(inv_met).any()=}\")\n",
    "assert not torch.isnan(inv_met).any(), \"NaN values found in inv_met, which could lead to instability. Consider increasing eps or checking the energy landscape for very low values.\"\n",
    "\n",
    "inv_inner_prods_pre: Tensor = torch.einsum('bij,bj->bi', inv_met, met_score)\n",
    "inv_inner_prod: Tensor = torch.einsum('bi,bi->b', inv_inner_prods_pre, met_score)\n",
    "\n",
    "assert not torch.isnan(inv_inner_prod).any(), \"NaN values found in inv_inner_prod, which could lead to instability. Consider increasing eps or checking the energy landscape for very low values.\"\n",
    "assert  not torch.isnan(inner_prods).any(), \"NaN values found in inner_prods, which could lead to instability. Consider increasing eps or checking the energy landscape for very low values.\"\n",
    "\n",
    "assert torch.all(inv_inner_prod > 0), \"Negative values found in inv_inner_prod, which could lead to instability. Consider increasing eps or checking the energy landscape for very low values.\"\n",
    "\n",
    "print(f\"{torch.isnan(inv_inner_prod).any()=}\")\n",
    "print(f\"{torch.linalg.norm(inv_inner_prod)=}\")\n",
    "\n",
    "beta_comp: Tensor = torch.sqrt( inv_inner_prod / inner_prods)\n",
    "\n",
    "print(f\"beta should be less than {beta_comp.min().item()} to fulfill the condition for a Randers metric\")\n",
    "if toy_metric.beta >= beta_comp.min().item():\n",
    "    print(\"Warning! beta is greater than the minimum value required for a Randers metric, which could lead to instability. Consider reducing beta or checking the energy landscape for very low values.\")\n",
    "\n",
    "print(f\"{inv_inner_prod.max().item()=}\")\n",
    "print(f\"{inner_prods.max().item()=}\")\n",
    "print(f\"{beta_comp.max().item()=}\")\n",
    "\n",
    "one_ov_sq: Tensor = 1  / torch.sqrt(inv_inner_prod + toy_metric.eps)\n",
    "assert not torch.any(torch.isnan(one_ov_sq)), \"NaN values found in one_ov_sq, which could lead to instability. Consider increasing eps or checking the energy landscape for very low values.\"\n",
    "# print(f\"{one_ov_sq.shape=}\")\n",
    "\n",
    "\n",
    "# if beta is less than the above value, we should not run into the assert below...\n",
    "\n",
    "einops.parse_shape(inv_met, 'b i j')\n",
    "einops.parse_shape(met_score, 'b i')\n",
    "einops.parse_shape(one_ov_sq, 'b')\n",
    "\n",
    "one_form: Tensor = toy_metric.beta * one_ov_sq[:, None] * met_score\n",
    "einops.parse_shape(one_form, 'b i')\n",
    "\n",
    "# calculating the norm of the one-form under A(x)\n",
    "\n",
    "pre_out: Tensor = torch.einsum('bij,bj->bi', A_mat , one_form)\n",
    "norm_one_form: Tensor = torch.einsum('bi,bi->b', pre_out, one_form)\n",
    "assert torch.all(norm_one_form < 1.0), f\"The norm of the one-form under A(x) should be less than 1 for stability reasons. Got an average of {norm_one_form.mean().item()} and a max of {norm_one_form.max().item()}\"\n",
    "\n",
    "print(f\"{norm_one_form.max().item()=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2e6fe8",
   "metadata": {},
   "source": [
    "# Visualizing the 1-form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f95290",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_metric_cfg: dict = {\n",
    "\"_target_\": \"train_EBM_geodesic.Method3Metric\",\n",
    "    \"a_num\": 20.0,\n",
    "    \"b_num\": 0.01,\n",
    "    \"eps\": 1e-6,\n",
    "    \"eta\": 0.1,\n",
    "    \"mu\": 1.0,\n",
    "    \"beta\": 0.1,\n",
    "    \"alpha_fn_choice\": \"linear\"\n",
    "}\n",
    "\n",
    "method3_metric: Method3Metric = hydra.utils.instantiate(target_metric_cfg, ebm=ebm)\n",
    "\n",
    "N_samples: int = 50\n",
    "x_p_subs, y_p_subs = torch.meshgrid(torch.linspace(-10, 10, N_samples), torch.linspace(-2.5, 10, N_samples), indexing='xy')\n",
    "pos_subs = torch.cat([x_p_subs.flatten().unsqueeze(1), y_p_subs.flatten().unsqueeze(1)], dim=1).to(DEVICE)\n",
    "\n",
    "pos_subs.requires_grad_(True)\n",
    "one_form_all: Tensor = method3_metric.one_form(pos_subs)\n",
    "print(f\"{one_form_all.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the one-form along with the landscape of A(x) for the Method3Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig: go.Figure = go.Figure()\n",
    "\n",
    "one_form_dtch: Tensor = one_form_all.detach().cpu().numpy()\n",
    "\n",
    "x_tnsr_subs: Tensor = pos_subs[:, 0].detach().cpu().numpy()\n",
    "y_tnsr_subs: Tensor = pos_subs[:, 1].detach().cpu().numpy()\n",
    "\n",
    "num_to_subsample: int = 1000\n",
    "one_form_dtch: Tensor = one_form_dtch\n",
    "\n",
    "scale_factor: float = 5.0\n",
    "fig_quiver = ff.create_quiver(\n",
    "    x=x_tnsr_subs,\n",
    "    y=y_tnsr_subs,\n",
    "    u=one_form_dtch[:, 0],\n",
    "    v=one_form_dtch[:, 1],\n",
    "    scale=scale_factor,\n",
    ")\n",
    "\n",
    "# set equal aspect ratio\n",
    "fig_quiver.update_layout(\n",
    "    title=f\"One-form Visualization for Method3Metric (Scale: {scale_factor})\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"y\",\n",
    "    xaxis=dict(scaleanchor=\"y\", scaleratio=1),\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    ")\n",
    "fig_quiver.show()\n",
    "\n",
    "# fig.add_trace(\n",
    "\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c69182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33016f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresh_ml_sdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
